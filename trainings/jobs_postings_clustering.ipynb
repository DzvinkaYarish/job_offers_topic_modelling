{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job descriptions clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,  TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data job posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobpost</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>AnnouncementCode</th>\n",
       "      <th>Term</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Audience</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ApplicationP</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Notes</th>\n",
       "      <th>AboutC</th>\n",
       "      <th>Attach</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMERIA Investment Consulting Company\\r\\nJOB TI...</td>\n",
       "      <td>Jan 5, 2004</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>AMERIA Investment Consulting Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To apply for this position, please submit a\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 January 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>International Research &amp; Exchanges Board (IREX...</td>\n",
       "      <td>Jan 7, 2004</td>\n",
       "      <td>Full-time Community Connections Intern (paid i...</td>\n",
       "      <td>International Research &amp; Exchanges Board (IREX)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 months</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please submit a cover letter and resume to:\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 January 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The International Research &amp; Exchanges Board (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             jobpost         date  \\\n",
       "0  AMERIA Investment Consulting Company\\r\\nJOB TI...  Jan 5, 2004   \n",
       "1  International Research & Exchanges Board (IREX...  Jan 7, 2004   \n",
       "\n",
       "                                               Title  \\\n",
       "0                            Chief Financial Officer   \n",
       "1  Full-time Community Connections Intern (paid i...   \n",
       "\n",
       "                                           Company AnnouncementCode Term  \\\n",
       "0             AMERIA Investment Consulting Company              NaN  NaN   \n",
       "1  International Research & Exchanges Board (IREX)              NaN  NaN   \n",
       "\n",
       "  Eligibility Audience StartDate  Duration  ...   Salary  \\\n",
       "0         NaN      NaN       NaN       NaN  ...      NaN   \n",
       "1         NaN      NaN       NaN  3 months  ...      NaN   \n",
       "\n",
       "                                        ApplicationP OpeningDate  \\\n",
       "0  To apply for this position, please submit a\\r\\...         NaN   \n",
       "1  Please submit a cover letter and resume to:\\r\\...         NaN   \n",
       "\n",
       "          Deadline Notes                                             AboutC  \\\n",
       "0  26 January 2004   NaN                                                NaN   \n",
       "1  12 January 2004   NaN  The International Research & Exchanges Board (...   \n",
       "\n",
       "  Attach  Year Month     IT  \n",
       "0    NaN  2004     1  False  \n",
       "1    NaN  2004     1  False  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['jobpost'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates('jobpost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated('jobpost').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data[\"jobpost\"], data[\"Title\"], test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [lemmatizer.lemmatize(w.lower()) for sent in sent_tokenize(text) for w in word_tokenize(sent) if w.isalpha() and len(w) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english', min_df=2, max_df=0.5, max_features=20000, tokenizer=lambda text:tokenizer(text))\n",
    "X = cv.fit_transform(data['jobpost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.5, max_features=20000, tokenizer=lambda text:tokenizer(text))\n",
    "X_tf = tfidf.fit_transform(data['jobpost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(learning_method=\"online\", max_iter=30, n_components=30)\n",
    "topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic probabilities: 0 \n",
      "job title: Chief Financial Officer\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Full-time Community Connections Intern (paid internship)\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Country Coordinator\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: BCC Specialist\n",
      "\n",
      "topic probabilities: 3 \n",
      "job title: Software Developer\n",
      "\n",
      "topic probabilities: 8 \n",
      "job title: Saleswoman\n",
      "\n",
      "topic probabilities: 0 \n",
      "job title: Chief Accountant/ Finance Assistant\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Non-paid part or full time Programmatic Intern\n",
      "\n",
      "topic probabilities: 8 \n",
      "job title: Assistant to Managing Director\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Program Assistant (INL), FSN-8; FP-6*\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Short-Term Travel Grants (STG) Program\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Non-paid part or full time Administrative Intern\n",
      "\n",
      "topic probabilities: 5 \n",
      "job title: Chief of Party (COP)\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Community Development, Capacity Building and Conflict\n",
      "\n",
      "topic probabilities: 8 \n",
      "job title: General Manager\n",
      "\n",
      "topic probabilities: 4 \n",
      "job title: Network Administrator\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Utopian World Championship 2004\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Country Economist (NOB)\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Driver/ Logistics Assistant\n",
      "\n",
      "topic probabilities: 3 \n",
      "job title: Graphic Designer\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Administrative Assistant\n",
      "\n",
      "topic probabilities: 7 \n",
      "job title: Lawyer\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Marketing Advisor\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Chief/ Supervisor of Programs Department\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Journalism Trainer\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Deputy Program Director\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Student Forum: Student Conference and Debate Forum (April 17 -\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Reporting Diversity Workshop for Journalists\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Reporting Diversity Workshop for Journalists\n",
      "\n",
      "topic probabilities: 0 \n",
      "job title: Chief Accountant\n",
      "\n",
      "topic probabilities: 8 \n",
      "job title: Consultant (short-term)\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Guard, FSN-2; FP-CC*\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Training Officer\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Chauffeur, FSN-3; FP-BB*\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: Demographic Analysis Workshop\n",
      "\n",
      "topic probabilities: 8 \n",
      "job title: Programmer\n",
      "\n",
      "topic probabilities: 3 \n",
      "job title: Tester\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Receptionist\n",
      "\n",
      "topic probabilities: 2 \n",
      "job title: German Internships for Young Practicing Journalists from NIS\n",
      "\n",
      "topic probabilities: 1 \n",
      "job title: Volunteer/ Intern\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Team Leader/ Chief of Party\n",
      "\n",
      "topic probabilities: 6 \n",
      "job title: Program Manager - Children's Programs\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "42",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c54e41c57b84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'topic probabilities: {} \\njob title: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dzvinka/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dzvinka/anaconda3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2475\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2477\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4404)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4087)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:14031)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:13975)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 42"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for i, topic in enumerate(topics[:50]):\n",
    "    print('topic: {} \\njob title: {}'.format(np.argmax(topic), data['Title'][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "--------------\n",
      "attitude\n",
      "confirming\n",
      "attracted\n",
      "expend\n",
      "laghajanyan\n",
      "ccm\n",
      "beijing\n",
      "artsakhbank\n",
      "evaluatior\n",
      "continually\n",
      "sapling\n",
      "census\n",
      "shelf\n",
      "qas\n",
      "specialty\n",
      "managing\n",
      "oldest\n",
      "portfolio\n",
      "kahavorum\n",
      "scotland\n",
      "frenchise\n",
      "ucs\n",
      "recruitarmenia\n",
      "aptitude\n",
      "evangelism\n",
      "analysing\n",
      "vxsoft\n",
      "rtos\n",
      "detached\n",
      "discarded\n",
      "Topic 1\n",
      "--------------\n",
      "sdas\n",
      "continually\n",
      "lover\n",
      "shelf\n",
      "qsquantum\n",
      "kurt\n",
      "lotus\n",
      "loaning\n",
      "bing\n",
      "rtos\n",
      "census\n",
      "telegate\n",
      "eunp\n",
      "cyprus\n",
      "beirut\n",
      "loan\n",
      "haymamul\n",
      "ncfas\n",
      "ccm\n",
      "klaus\n",
      "loaded\n",
      "advertises\n",
      "stornquist\n",
      "predominant\n",
      "streamlined\n",
      "oldest\n",
      "struggling\n",
      "polishing\n",
      "shahamiryans\n",
      "preselling\n",
      "Topic 2\n",
      "--------------\n",
      "sold\n",
      "daban\n",
      "curatorial\n",
      "czech\n",
      "webcall\n",
      "testcompleat\n",
      "teamviewer\n",
      "tevaresume\n",
      "technolinguistics\n",
      "ea\n",
      "rabbitmq\n",
      "quite\n",
      "tectonics\n",
      "inconcept\n",
      "kurt\n",
      "sra\n",
      "chance\n",
      "coorditation\n",
      "preselling\n",
      "qsquantum\n",
      "shahinyan\n",
      "cyprus\n",
      "som\n",
      "biomass\n",
      "postion\n",
      "reconfirm\n",
      "toolkit\n",
      "synthetic\n",
      "flooding\n",
      "shelf\n",
      "Topic 3\n",
      "--------------\n",
      "edication\n",
      "breakpoint\n",
      "ophthalmologic\n",
      "araratfood\n",
      "chemoincs\n",
      "neonatal\n",
      "archivation\n",
      "enroll\n",
      "rome\n",
      "glow\n",
      "optimising\n",
      "episode\n",
      "democratization\n",
      "wva\n",
      "digging\n",
      "downtown\n",
      "automatically\n",
      "sagarko\n",
      "wi\n",
      "accordance\n",
      "neurology\n",
      "jet\n",
      "marketer\n",
      "gali\n",
      "nominated\n",
      "gentoo\n",
      "valeriagrogoryan\n",
      "list\n",
      "avatar\n",
      "dependability\n",
      "Topic 4\n",
      "--------------\n",
      "ndrmp\n",
      "arakishvili\n",
      "extjs\n",
      "current\n",
      "agenciesand\n",
      "ado\n",
      "informatively\n",
      "bioinformatics\n",
      "mailbox\n",
      "flooding\n",
      "dish\n",
      "posting\n",
      "gps\n",
      "transmitted\n",
      "effort\n",
      "wtms\n",
      "developement\n",
      "arisen\n",
      "competitave\n",
      "semrubo\n",
      "raed\n",
      "cgs\n",
      "pm\n",
      "immediatelly\n",
      "tun\n",
      "fiscal\n",
      "teammate\n",
      "publishes\n",
      "teamleader\n",
      "kols\n",
      "Topic 5\n",
      "--------------\n",
      "accounted\n",
      "evaluatior\n",
      "accountancy\n",
      "tba\n",
      "evaluating\n",
      "jun\n",
      "rjaffe\n",
      "ashkhatakazm\n",
      "prost\n",
      "carrier\n",
      "broken\n",
      "broaden\n",
      "comforting\n",
      "accossires\n",
      "justice\n",
      "jeopardise\n",
      "rmd\n",
      "ccm\n",
      "humoured\n",
      "transcontinental\n",
      "referendum\n",
      "pmic\n",
      "kurt\n",
      "attitude\n",
      "standup\n",
      "statistical\n",
      "horeca\n",
      "rtos\n",
      "loan\n",
      "hunt\n",
      "Topic 6\n",
      "--------------\n",
      "nava\n",
      "sheet\n",
      "administratively\n",
      "winemaking\n",
      "fp\n",
      "sold\n",
      "sett\n",
      "historical\n",
      "administrating\n",
      "atinfo\n",
      "igra\n",
      "history\n",
      "clustered\n",
      "tectonics\n",
      "eduction\n",
      "listener\n",
      "italian\n",
      "technolinguistics\n",
      "coorditation\n",
      "clustering\n",
      "condiment\n",
      "hdp\n",
      "unjustified\n",
      "trout\n",
      "manushyan\n",
      "rcc\n",
      "teamviewer\n",
      "knowladge\n",
      "caversham\n",
      "wanting\n",
      "Topic 7\n",
      "--------------\n",
      "rabbitmq\n",
      "questrades\n",
      "daban\n",
      "oldest\n",
      "loan\n",
      "hunt\n",
      "tranche\n",
      "activites\n",
      "supportspecialist\n",
      "staircase\n",
      "grilling\n",
      "rdbm\n",
      "ecac\n",
      "haymamul\n",
      "administrational\n",
      "retraining\n",
      "chromatography\n",
      "arplanllc\n",
      "rjaffe\n",
      "dispense\n",
      "carry\n",
      "reasonably\n",
      "lakeside\n",
      "guaranty\n",
      "reta\n",
      "loaning\n",
      "prima\n",
      "deprived\n",
      "quickly\n",
      "shelf\n",
      "Topic 8\n",
      "--------------\n",
      "conceiving\n",
      "cdc\n",
      "informant\n",
      "honored\n",
      "lie\n",
      "sovereign\n",
      "honor\n",
      "karapetyan\n",
      "style\n",
      "malak\n",
      "euroset\n",
      "testcompleat\n",
      "calibration\n",
      "mulberry\n",
      "frontires\n",
      "negotiator\n",
      "employmnt\n",
      "ask\n",
      "textured\n",
      "responsibe\n",
      "bing\n",
      "park\n",
      "lusavorchi\n",
      "focus\n",
      "frictionless\n",
      "pharmaceutic\n",
      "coded\n",
      "stylevision\n",
      "fall\n",
      "totally\n",
      "Topic 9\n",
      "--------------\n",
      "renovation\n",
      "accounted\n",
      "ore\n",
      "administrational\n",
      "competitve\n",
      "cement\n",
      "respondent\n",
      "visual\n",
      "unloading\n",
      "ansa\n",
      "aplliances\n",
      "upselling\n",
      "mailarm\n",
      "biochemistry\n",
      "python\n",
      "cma\n",
      "psychosocial\n",
      "ungo\n",
      "vonages\n",
      "retraining\n",
      "hi\n",
      "reccomendations\n",
      "prudently\n",
      "responding\n",
      "christin\n",
      "renewed\n",
      "fleurs\n",
      "marneuli\n",
      "diet\n",
      "digest\n"
     ]
    }
   ],
   "source": [
    "features = cv.get_feature_names()\n",
    "sortings = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "for i, sort in enumerate(sortings):\n",
    "    print('Topic {}'.format(i))\n",
    "    print('--------------')\n",
    "    for indx in sort[:30]:\n",
    "        print(features[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "medical       office        recruitment   management    marketing     \n",
      "representativeadministrativefashion       ensure        market        \n",
      "pharmaceuticalassistant     fao           business      business      \n",
      "visit         document      official      process       development   \n",
      "doctor        maintain      curriculum    manage        develop       \n",
      "medicine      duty          contact       manager       product       \n",
      "office        provide       vitae         plan          strategy      \n",
      "healthcare    assist        distributor   develop       plan          \n",
      "university    perform       zeppelin      activity      research      \n",
      "interpersonal meeting       information   performance   new           \n",
      "information   staff         adviser       staff         activity      \n",
      "regular       correspondencearka          policy        advertising   \n",
      "le            relevant      arge          control       implement     \n",
      "pay           task          motor         operation     potential     \n",
      "liability     translation   agency        provide       conduct       \n",
      "promote       prepare       vallex        department    chain         \n",
      "general       support       current       planning      material      \n",
      "capable       written       simulation    resource      analysis      \n",
      "organizationalmake          sonics        report        organize      \n",
      "fluency       information   tanger        internal      value         \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "child         mobile        credit        orange        procurement   \n",
      "community     european      data          tumo          custom        \n",
      "development   europe        card          embedded      supplier      \n",
      "world         million       analysis      exam          piu           \n",
      "vision        question      higher        club          logistics     \n",
      "ensure        german        education     calculate     forest        \n",
      "health        game          risk          pharmacy      prepare       \n",
      "program       reference     specialist    air           international \n",
      "adp           offer         copy          heating       mining        \n",
      "support       world         program       surname       supply        \n",
      "staff         tool          economic      registered    purchase      \n",
      "implementationtechnical     io            hospital      import        \n",
      "quality       team          report        teach         giz           \n",
      "family        stress        statistic     azatutyan     order         \n",
      "activity      visit         monitoring    creative      inventory     \n",
      "team          regarding     statistical   webb          transportation\n",
      "local         support       case          fontaine      bid           \n",
      "provide       hrm           survey        higher        purchasing    \n",
      "protection    french        document      gas           management    \n",
      "marz          gmbh          analyze       residential   process       \n",
      "\n",
      "\n",
      "topic 10      topic 11      topic 12      topic 13      topic 14      \n",
      "--------      --------      --------      --------      --------      \n",
      "customer      course        amd           student       open          \n",
      "sale          level         welcome       education     apply         \n",
      "service       business      remuneration  school        criterion     \n",
      "product       class         group         program       note          \n",
      "client        test          associate     university    eligibility   \n",
      "manager       group         acceptance    american      additional    \n",
      "llc           professional  ojsc          applicant     register      \n",
      "retail        student       client        study         registration  \n",
      "store         epam          tda           state         resume        \n",
      "responsible   final         troika        academic      individual    \n",
      "new           material      oxfam         international receive       \n",
      "corporate     according     incumbent     art           process       \n",
      "team          certificate   partner       institution   possible      \n",
      "presentation  ha            proficiency   united        house         \n",
      "creative      additional    attention     professional  interview     \n",
      "strong        office        discretion    curriculum    month         \n",
      "personality   intended      send          foundation    attach        \n",
      "brand         hour          starting      country       right         \n",
      "send          study         day           undergraduate employment    \n",
      "account       using         maac          higher        soon          \n",
      "\n",
      "\n",
      "topic 15      topic 16      topic 17      topic 18      topic 19      \n",
      "--------      --------      --------      --------      --------      \n",
      "software      android       form          loan          design        \n",
      "development   haypost       attachment    branch        web           \n",
      "team          corner        training      service       graphic       \n",
      "developer     attask        http          client        cjsc          \n",
      "test          prometey      following     office        javascript    \n",
      "testing       picsart       downloaded    lending       php           \n",
      "technical     forwarding    attached      cjsc          html          \n",
      "project       iom           field         finca         software      \n",
      "design        visiting      education     portfolio     designer      \n",
      "technology    git           graduate      gyumri        plus          \n",
      "develop       aecp          considered    activity      programming   \n",
      "product       macadamian    click         monitoring    synopsys      \n",
      "database      hrmanager     information   operation     cs            \n",
      "solution      canada        complete      committee     service       \n",
      "code          photocopy     specialist    kamurj        strong        \n",
      "requirement   thank         confirmation  potential     user          \n",
      "sql           utah          previously    mission       automation    \n",
      "java          hanrapetutyan asap          repayment     long          \n",
      "llc           exploration   peace         boomerang     eda           \n",
      "quality       sdk           volunteer     borrower      adobe         \n",
      "\n",
      "\n",
      "topic 20      topic 21      topic 22      topic 23      topic 24      \n",
      "--------      --------      --------      --------      --------      \n",
      "insurance     bank          project       qualified     project       \n",
      "holding       financial     program       llc           development   \n",
      "cascade       accounting    development   line          implementation\n",
      "procredit     finance       activity      field         international \n",
      "capital       report        international open          programme     \n",
      "bank          banking       support       eligibility   government    \n",
      "cjsc          tax           management    criterion     management    \n",
      "internship    prepare       training      long          national      \n",
      "intern        legislation   team          interview     sector        \n",
      "cafesjian     accountant    including     cjsc          service       \n",
      "service       audit         public        plus          consultant    \n",
      "indicate      internal      social        computer      policy        \n",
      "established   cash          staff         responsible   activity      \n",
      "development   account       local         send          support       \n",
      "group         control       report        asap          report        \n",
      "icjsc         cjsc          information   cv            technical     \n",
      "soft          related       foundation    applying      relevant      \n",
      "foundation    chief         assist        university    expert        \n",
      "contacted     payment       provide       team          area          \n",
      "looking       software      working       strong        country       \n",
      "\n",
      "\n",
      "topic 25      topic 26      topic 27      topic 28      topic 29      \n",
      "--------      --------      --------      --------      --------      \n",
      "health        legal         network       hotel         construction  \n",
      "care          office        service       driving       engineering   \n",
      "patient       law           technical     license       production    \n",
      "msf           medium        information   vehicle       equipment     \n",
      "drug          caucasus      support       education     engineer      \n",
      "treatment     osce          security      higher        technical     \n",
      "france        right         responsible   food          design        \n",
      "pharmacist    international telecommunicationdaily         shop          \n",
      "committee     human         cjsc          guest         electrical    \n",
      "ticket        public        computer      driver        quality       \n",
      "sans          national      database      send          tourism       \n",
      "logistic      regional      server        maintain      site          \n",
      "moh           programme     maintenance   service       material      \n",
      "prison        civil         administrationensure        tour          \n",
      "corresponding draft         equipment     agent         control       \n",
      "bridge        political     field         assigned      standard      \n",
      "archiving     information   administrator order         industrial    \n",
      "resistant     news          specialist    responsible   mechanical    \n",
      "tuberculosis  research      window        trade         industry      \n",
      "motivation    relation      hardware      stock         drawing       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(cv.get_feature_names())\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(30), feature_names=feature_names,\n",
    "sorting=sorting, topics_per_chunk=5, n_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-757800dd1e32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkm_10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkm_10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dzvinka/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                 return_n_iter=True)\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dzvinka/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[1;31m# determine if these results are the best so far\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dzvinka/anaconda3/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m             centers = _k_means._centers_sparse(X, labels, n_clusters,\n\u001b[1;32m--> 498\u001b[1;33m                                                distances)\n\u001b[0m\u001b[0;32m    499\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_k_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_centers_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "km_10 = KMeans(n_clusters=10)\n",
    "km_10.fit(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'cluster_centers_'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-24c635224323>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0morder_centroids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm_10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cluster %d:\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'cluster_centers_'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "order_centroids = km_10.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(10):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :30]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_5 = KMeans(n_clusters=5)\n",
    "km_5.fit(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: accounting financial accountant tax finance report chief prepare account legislation\n",
      "Cluster 1: software development developer design web test team testing engineer java\n",
      "Cluster 2: project program development management training international implementation activity community office\n",
      "Cluster 3: sale customer marketing llc service responsible manager product office business\n",
      "Cluster 4: bank credit banking loan cjsc form financial branch customer attachment\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km_5.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(5):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}